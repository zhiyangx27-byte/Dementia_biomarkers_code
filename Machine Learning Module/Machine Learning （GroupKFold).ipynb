{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning via Generalized Linear Model (GLM) and Firth Logistic Regression (FLR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29bc20bb364870a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose is to generate a new data-table, whose row is the unique characteristic of each donor, containing the ID, the type (AD or control), the subclass and the expression condition of each gene etc.\n",
    "To do this, the first thing to do is to arrange the dispersive single-cell dataset into the form of the targeted new data-table."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1eba3c22464c24eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the packages we want:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ecc46072e09030d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:39:43.091918Z",
     "start_time": "2025-10-06T12:39:40.556809Z"
    }
   },
   "id": "7ffdd894a377b6fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the original data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82395b8ea74ec4cf"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(\"/Users/a1234/Desktop/Donor metadata.xlsx\")\n",
    "mtg = pd.read_excel(\"/Users/a1234/Desktop/Quantitative neuropathology summary data (MTG).xlsx\")\n",
    "omics_folder = \"/Users/a1234/Desktop/Omics data (scRNA-seq)/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:39:44.902937Z",
     "start_time": "2025-10-06T12:39:44.550572Z"
    }
   },
   "id": "fb893380d8019b34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Format example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9802a15bf275ea5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "omics_example = sc.read_h5ad(\"/Users/a1234/Desktop/Omics data (scRNA-seq)/H21.33.002_SEAAD_MTG_RNAseq_final-nuclei.2024-02-13.h5ad\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:39:50.691171Z",
     "start_time": "2025-10-06T12:39:46.222681Z"
    }
   },
   "id": "52fcc473b7832c51"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "AnnData object with n_obs × n_vars = 15761 × 36601\n    obs: 'sample_id', 'Neurotypical reference', 'Donor ID', 'Organism', 'Brain Region', 'Sex', 'Gender', 'Age at Death', 'Race (choice=White)', 'Race (choice=Black/ African American)', 'Race (choice=Asian)', 'Race (choice=American Indian/ Alaska Native)', 'Race (choice=Native Hawaiian or Pacific Islander)', 'Race (choice=Unknown or unreported)', 'Race (choice=Other)', 'specify other race', 'Hispanic/Latino', 'Highest level of education', 'Years of education', 'PMI', 'Fresh Brain Weight', 'Brain pH', 'Overall AD neuropathological Change', 'Thal', 'Braak', 'CERAD score', 'Overall CAA Score', 'Highest Lewy Body Disease', 'Total Microinfarcts (not observed grossly)', 'Total microinfarcts in screening sections', 'Atherosclerosis', 'Arteriolosclerosis', 'LATE', 'Cognitive Status', 'Last CASI Score', 'Interval from last CASI in months', 'Last MMSE Score', 'Interval from last MMSE in months', 'Last MOCA Score', 'Interval from last MOCA in months', 'APOE Genotype', 'Primary Study Name', 'Secondary Study Name', 'NeuN positive fraction on FANS', 'RIN', 'cell_prep_type', 'facs_population_plan', 'rna_amplification', 'sample_name', 'sample_quantity_count', 'expc_cell_capture', 'method', 'pcr_cycles', 'percent_cdna_longer_than_400bp', 'rna_amplification_pass_fail', 'amplified_quantity_ng', 'load_name', 'library_prep', 'library_input_ng', 'r1_index', 'avg_size_bp', 'quantification_fmol', 'library_prep_pass_fail', 'exp_component_vendor_name', 'batch_vendor_name', 'experiment_component_failed', 'alignment', 'Genome', 'ar_id', 'bc', 'GEX_Estimated_number_of_cells', 'GEX_number_of_reads', 'GEX_sequencing_saturation', 'GEX_Mean_raw_reads_per_cell', 'GEX_Q30_bases_in_barcode', 'GEX_Q30_bases_in_read_2', 'GEX_Q30_bases_in_UMI', 'GEX_Percent_duplicates', 'GEX_Q30_bases_in_sample_index_i1', 'GEX_Q30_bases_in_sample_index_i2', 'GEX_Reads_with_TSO', 'GEX_Sequenced_read_pairs', 'GEX_Valid_UMIs', 'GEX_Valid_barcodes', 'GEX_Reads_mapped_to_genome', 'GEX_Reads_mapped_confidently_to_genome', 'GEX_Reads_mapped_confidently_to_intergenic_regions', 'GEX_Reads_mapped_confidently_to_intronic_regions', 'GEX_Reads_mapped_confidently_to_exonic_regions', 'GEX_Reads_mapped_confidently_to_transcriptome', 'GEX_Reads_mapped_antisense_to_gene', 'GEX_Fraction_of_transcriptomic_reads_in_cells', 'GEX_Total_genes_detected', 'GEX_Median_UMI_counts_per_cell', 'GEX_Median_genes_per_cell', 'Multiome_Feature_linkages_detected', 'Multiome_Linked_genes', 'Multiome_Linked_peaks', 'ATAC_Confidently_mapped_read_pairs', 'ATAC_Fraction_of_genome_in_peaks', 'ATAC_Fraction_of_high_quality_fragments_in_cells', 'ATAC_Fraction_of_high_quality_fragments_overlapping_TSS', 'ATAC_Fraction_of_high_quality_fragments_overlapping_peaks', 'ATAC_Fraction_of_transposition_events_in_peaks_in_cells', 'ATAC_Mean_raw_read_pairs_per_cell', 'ATAC_Median_high_quality_fragments_per_cell', 'ATAC_Non-nuclear_read_pairs', 'ATAC_Number_of_peaks', 'ATAC_Percent_duplicates', 'ATAC_Q30_bases_in_barcode', 'ATAC_Q30_bases_in_read_1', 'ATAC_Q30_bases_in_read_2', 'ATAC_Q30_bases_in_sample_index_i1', 'ATAC_Sequenced_read_pairs', 'ATAC_TSS_enrichment_score', 'ATAC_Unmapped_read_pairs', 'ATAC_Valid_barcodes', 'Number of mapped reads', 'Number of unmapped reads', 'Number of multimapped reads', 'Number of reads', 'Number of UMIs', 'Genes detected', 'Doublet score', 'Fraction mitochondrial UMIs', 'Used in analysis', 'Class confidence', 'Class', 'Subclass confidence', 'Subclass', 'Supertype confidence', 'Supertype (non-expanded)', 'Supertype', 'Continuous Pseudo-progression Score', 'Severely Affected Donor'\n    var: 'gene_ids'\n    uns: 'APOE4 Status_colors', 'Braak_colors', 'CERAD score_colors', 'Cognitive Status_colors', 'Great Apes Metadata', 'Highest Lewy Body Disease_colors', 'LATE_colors', 'Overall AD neuropathological Change_colors', 'Sex_colors', 'Subclass_colors', 'Supertype_colors', 'Thal_colors', 'UW Clinical Metadata', 'X_normalization', 'batch_condition', 'default_embedding', 'neighbors', 'title', 'umap'\n    obsm: 'X_scVI', 'X_umap'\n    layers: 'UMIs'\n    obsp: 'connectivities', 'distances'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omics_example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:39:50.697826Z",
     "start_time": "2025-10-06T12:39:50.693754Z"
    }
   },
   "id": "24c324f40142d8f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now generate the targeted dataset which is used for further machine learning:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8a89283b3fc9715"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we deal with the omics data:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104a598f4a9f3e7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "omics_files = [f for f in os.listdir(omics_folder) if f.endswith('.h5ad')]\n",
    "\n",
    "donor_ids = [f.split('_')[0] for f in omics_files]\n",
    "\n",
    "omics_data = []\n",
    "\n",
    "for i, file in enumerate(omics_files):\n",
    "    adata = sc.read_h5ad(os.path.join(omics_folder, file))\n",
    "    \n",
    "    obs_data = adata.obs[[\"Thal\", \"Braak\", \"Overall CAA Score\", \"Last MMSE Score\", \"NeuN positive fraction on FANS\", \"Fraction mitochondrial UMIs\", \"Number of UMIs\", \"Doublet score\", \"Class\", \"Subclass\"]].copy()\n",
    "    \n",
    "    obs_data['Donor_ID'] = donor_ids[i]\n",
    "    \n",
    "    omics_data.append(obs_data)\n",
    "\n",
    "omics_data_df = pd.concat(omics_data)\n",
    "\n",
    "# omics_data_df.to_csv(\"omics_data(with gene related).csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:45:27.172899Z",
     "start_time": "2025-10-06T12:39:55.896731Z"
    }
   },
   "id": "386c1a62e1643da8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "omics_data_df = omics_data_df.rename(columns={'Donor_ID': 'Donor ID'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:46.000581Z",
     "start_time": "2025-10-06T12:46:45.814089Z"
    }
   },
   "id": "74819d0fdc7feea6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Extract Donor_ID from Omics data\n",
    "donor_ids = [file.split('_')[0] for file in omics_files if file.endswith('.h5ad')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:46.703842Z",
     "start_time": "2025-10-06T12:46:46.673881Z"
    }
   },
   "id": "2d6b9be473cb200e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Find out the common Donor_ID\n",
    "common_donor_ids = set(metadata['Donor ID']).intersection(set(mtg['Donor ID'])).intersection(set(donor_ids))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:47.221166Z",
     "start_time": "2025-10-06T12:46:47.200890Z"
    }
   },
   "id": "29f5a97b6febdc16"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# For metadata\n",
    "metadata_filtered = metadata[metadata['Donor ID'].isin(common_donor_ids)][['Donor ID', 'Age at Death', 'Sex', 'Highest level of education', 'Cognitive Status', 'Overall AD neuropathological Change','PMI', 'RIN','LATE', 'Years of education']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:47.689503Z",
     "start_time": "2025-10-06T12:46:47.668217Z"
    }
   },
   "id": "5c07e161fd7b395a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Deal with the corresponding 'Race' columns in metadata\n",
    "race_columns = [col for col in metadata.columns if 'Race' in col]\n",
    "\n",
    "race_info = metadata[['Donor ID'] + race_columns].copy()\n",
    "\n",
    "race_info.loc[:,'Race'] = race_info.apply(get_race, axis=1)\n",
    "\n",
    "metadata_filtered = pd.merge(metadata_filtered, race_info[['Donor ID', 'Race']], on='Donor ID', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:58.997715Z",
     "start_time": "2025-10-06T12:46:58.947022Z"
    }
   },
   "id": "9e3e0a44e538f976"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Deal with the corresponding 'Consensus Clinical Dx' columns in metadata\n",
    "ccdx_columns = [col for col in metadata.columns if 'Consensus Clinical Dx' in col]\n",
    "\n",
    "ccdx_info = metadata[['Donor ID'] + ccdx_columns]\n",
    "\n",
    "ccdx_info = metadata[['Donor ID'] + ccdx_columns].copy()\n",
    "\n",
    "ccdx_info.loc[:,'Consensus Clinical Dx'] = ccdx_info.apply(get_ccdx, axis=1)\n",
    "\n",
    "metadata_filtered = pd.merge(metadata_filtered, ccdx_info[['Donor ID', 'Consensus Clinical Dx']], on='Donor ID', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:46:59.456305Z",
     "start_time": "2025-10-06T12:46:59.443707Z"
    }
   },
   "id": "44bfb279ba33920c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we deal with the quantitative neuropathology summary data (MTG):\n",
    "\n",
    "In this part, we select some of the columns of MTG based on domain knowledge."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f9572297565fc2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Extract useful data from Quantitative neuropathology summary data\n",
    "mtg_filtered = mtg.loc[\n",
    "    mtg['Donor ID'].isin(common_donor_ids),  \n",
    "    ['Donor ID',\n",
    "    'total AT8 positive area_Grey matter', \n",
    "    'number of AT8 positive cells_Grey matter', \n",
    "    'average AT8 positive cell area_Grey matter',\n",
    "    'total pTDP43 positive area_Grey matter', \n",
    "    'number of pTDP43 positive cells_Grey matter',\n",
    "    'total Iba1 positive area_Grey matter', \n",
    "    'number of Iba1 positive cells_Grey matter', \n",
    "    'number of activated Iba1 positive cells_Grey matter',\n",
    "    'number of 6e10 positive objects_Grey matter'\n",
    "    ]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:47:00.895559Z",
     "start_time": "2025-10-06T12:47:00.570622Z"
    }
   },
   "id": "547f9303ebcbc477"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "merged_data = pd.merge(metadata_filtered, mtg_filtered, on = 'Donor ID', how = 'inner')\n",
    "merged_data = pd.merge(merged_data, omics_data_df, on = 'Donor ID', how = 'inner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:47:02.055652Z",
     "start_time": "2025-10-06T12:47:01.486311Z"
    }
   },
   "id": "8d54c5f744330418"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "merge_data = merged_data.copy()\n",
    "\n",
    "continuous_cols = merge_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "categorical_cols = merge_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in categorical_cols if c != \"Donor ID\"]\n",
    "\n",
    "cont_agg = merge_data.groupby(\"Donor ID\")[continuous_cols].mean()\n",
    "\n",
    "def mode_or_unknown(x):\n",
    "    m = x.mode()\n",
    "    return m.iloc[0] if not m.empty else \"Unknown\"\n",
    "\n",
    "cat_agg = merge_data.groupby(\"Donor ID\")[categorical_cols].agg(mode_or_unknown)\n",
    "\n",
    "subclass_counts = (\n",
    "    merge_data.groupby([\"Donor ID\", \"Subclass\"],observed=False)\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "subclass_freq = subclass_counts.div(subclass_counts.sum(axis=1), axis=0)\n",
    "\n",
    "class_counts = (\n",
    "    merge_data.groupby([\"Donor ID\", \"Class\"],observed=False)\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "class_freq = class_counts.div(subclass_counts.sum(axis=1), axis=0)\n",
    "\n",
    "donor_level_df = cont_agg.join(cat_agg).join(subclass_freq).join(class_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:47:17.141489Z",
     "start_time": "2025-10-06T12:47:15.554886Z"
    }
   },
   "id": "194ebb2014a70b11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "“donor_level_df” is the washed dataset and it is the original dataset we will use in the machine learning:\n",
    "Note that we have already transform the cell-level data into donor-level data, and by doing this, we do the above steps:\n",
    "For the continuous variables: we use the mean value to replace the individual values;\n",
    "For separated variable: we count the frequencies of each of them (here, they are the columns --- \"Class\" and \"Subclass\");\n",
    "For others: we select the mode.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d89afcd151dac5f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions used in the process of data preparation:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a5013d1aa79deac"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Deal with the information of the set of 'Race' in metadata\n",
    "def get_race(row):\n",
    "    races = []\n",
    "    for col in race_columns:\n",
    "        if row[col] == 'Checked':\n",
    "            race = col.split('choice=')[1].split(')')[0]\n",
    "            races.append(race)\n",
    "    return ', '.join(races) if races else 'Unknown'\n",
    "\n",
    "# Deal with the information of the set of 'Consensus Clinical Dx' in metadata\n",
    "def get_ccdx(row):\n",
    "    ccdx = []\n",
    "    for col in ccdx_columns:\n",
    "        if row[col] == 'Checked':\n",
    "            diagnosis = col.split('choice=')[1].split(')')[0]\n",
    "            ccdx.append(diagnosis)\n",
    "    return ', '.join(ccdx) if ccdx else 'Unknown'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T12:47:19.252429Z",
     "start_time": "2025-10-06T12:47:19.226331Z"
    }
   },
   "id": "45a02e60c52daf23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning through pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20b38e1469b63c92"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer, roc_auc_score, average_precision_score, brier_score_loss, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:10.430494Z",
     "start_time": "2025-10-06T13:00:10.414404Z"
    }
   },
   "id": "54209623720ef7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Defining features: Donor-level data, excluding the target variable \"Cognitive Status\" and \"Donor ID\"\n",
    "X_raw = donor_level_df.drop('Cognitive Status', axis=1).reset_index()\n",
    "Y = donor_level_df['Cognitive Status'].values\n",
    "groups = X_raw['Donor ID'].values\n",
    "X = X_raw.drop('Donor ID', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:11.249705Z",
     "start_time": "2025-10-06T13:00:11.247684Z"
    }
   },
   "id": "ba3ced3cdca806cf"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "    Age at Death       PMI   RIN  Years of education  \\\n0           80.0  8.133333  8.33                17.0   \n1           82.0  7.700000  8.60                16.0   \n2           97.0  4.333333  7.87                12.0   \n3           86.0  8.833333  7.83                15.0   \n4           99.0  7.600000  8.40                12.0   \n..           ...       ...   ...                 ...   \n78          95.0  4.400000  7.27                16.0   \n79          88.0  7.000000  8.63                15.0   \n80          94.0  4.000000  6.55                12.0   \n81          97.0  7.000000  7.28                17.0   \n82          90.0  4.400000  8.70                21.0   \n\n    total AT8 positive area_Grey matter  \\\n0                          1.047120e+04   \n1                          5.798206e+04   \n2                          7.280875e+03   \n3                          7.556641e+05   \n4                          8.481321e+04   \n..                                  ...   \n78                         2.739650e+04   \n79                         1.009349e+06   \n80                         6.336955e+06   \n81                         2.329598e+05   \n82                         4.214846e+04   \n\n    number of AT8 positive cells_Grey matter  \\\n0                                        0.0   \n1                                       42.0   \n2                                        1.0   \n3                                      371.0   \n4                                        1.0   \n..                                       ...   \n78                                       6.0   \n79                                     199.0   \n80                                    1561.0   \n81                                      88.0   \n82                                       9.0   \n\n    average AT8 positive cell area_Grey matter  \\\n0                                     0.000000   \n1                                   102.924044   \n2                                    26.316354   \n3                                    80.896970   \n4                                    35.419410   \n..                                         ...   \n78                                   77.544874   \n79                                   82.742644   \n80                                   69.949808   \n81                                   83.979676   \n82                                   74.211618   \n\n    total pTDP43 positive area_Grey matter  \\\n0                                 0.000000   \n1                              2876.068832   \n2                                 0.000000   \n3                                 0.000000   \n4                                 0.000000   \n..                                     ...   \n78                                0.000000   \n79                                0.000000   \n80                            32320.361940   \n81                                0.000000   \n82                                0.000000   \n\n    number of pTDP43 positive cells_Grey matter  \\\n0                                           0.0   \n1                                          24.0   \n2                                           0.0   \n3                                           0.0   \n4                                           0.0   \n..                                          ...   \n78                                          0.0   \n79                                          0.0   \n80                                        960.0   \n81                                          0.0   \n82                                          0.0   \n\n    total Iba1 positive area_Grey matter  ...      Pax6     Pvalb      Sncg  \\\n0                              3552174.0  ...  0.008604  0.079063  0.012164   \n1                              4237830.0  ...  0.004955  0.062660  0.009359   \n2                              1790954.0  ...  0.008414  0.064703  0.022922   \n3                              4284872.0  ...  0.006153  0.072510  0.015524   \n4                              2984593.0  ...  0.007098  0.063704  0.015899   \n..                                   ...  ...       ...       ...       ...   \n78                             2527673.0  ...  0.008264  0.073509  0.024392   \n79                             6367609.0  ...  0.012921  0.042431  0.026320   \n80                             5981221.0  ...  0.013160  0.045036  0.039187   \n81                              977078.0  ...  0.006675  0.072370  0.024943   \n82                             2347377.0  ...  0.008280  0.080457  0.044259   \n\n         Sst  Sst Chodl      VLMC       Vip Neuronal: GABAergic  \\\n0   0.051660   0.002108  0.003352  0.086561            0.295622   \n1   0.018818   0.000801  0.004604  0.071168            0.212402   \n2   0.031530   0.001016  0.001499  0.069491            0.253397   \n3   0.027736   0.001136  0.003171  0.074404            0.251751   \n4   0.020571   0.000652  0.004455  0.089816            0.258293   \n..       ...        ...       ...       ...                 ...   \n78  0.041586   0.001000  0.002932  0.107298            0.316295   \n79  0.028075   0.000319  0.005264  0.083107            0.233371   \n80  0.027782   0.000292  0.016815  0.087586            0.305746   \n81  0.027578   0.001230  0.005621  0.115054            0.324785   \n82  0.081849   0.001539  0.001539  0.108888            0.394006   \n\n   Neuronal: Glutamatergic Non-neuronal and Non-neural  \n0                 0.521373                    0.183006  \n1                 0.615735                    0.171863  \n2                 0.584748                    0.161855  \n3                 0.595418                    0.152830  \n4                 0.584673                    0.157033  \n..                     ...                         ...  \n78                0.481106                    0.202599  \n79                0.525443                    0.241187  \n80                0.471122                    0.223132  \n81                0.499210                    0.176006  \n82                0.452407                    0.153587  \n\n[83 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age at Death</th>\n      <th>PMI</th>\n      <th>RIN</th>\n      <th>Years of education</th>\n      <th>total AT8 positive area_Grey matter</th>\n      <th>number of AT8 positive cells_Grey matter</th>\n      <th>average AT8 positive cell area_Grey matter</th>\n      <th>total pTDP43 positive area_Grey matter</th>\n      <th>number of pTDP43 positive cells_Grey matter</th>\n      <th>total Iba1 positive area_Grey matter</th>\n      <th>...</th>\n      <th>Pax6</th>\n      <th>Pvalb</th>\n      <th>Sncg</th>\n      <th>Sst</th>\n      <th>Sst Chodl</th>\n      <th>VLMC</th>\n      <th>Vip</th>\n      <th>Neuronal: GABAergic</th>\n      <th>Neuronal: Glutamatergic</th>\n      <th>Non-neuronal and Non-neural</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80.0</td>\n      <td>8.133333</td>\n      <td>8.33</td>\n      <td>17.0</td>\n      <td>1.047120e+04</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3552174.0</td>\n      <td>...</td>\n      <td>0.008604</td>\n      <td>0.079063</td>\n      <td>0.012164</td>\n      <td>0.051660</td>\n      <td>0.002108</td>\n      <td>0.003352</td>\n      <td>0.086561</td>\n      <td>0.295622</td>\n      <td>0.521373</td>\n      <td>0.183006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>82.0</td>\n      <td>7.700000</td>\n      <td>8.60</td>\n      <td>16.0</td>\n      <td>5.798206e+04</td>\n      <td>42.0</td>\n      <td>102.924044</td>\n      <td>2876.068832</td>\n      <td>24.0</td>\n      <td>4237830.0</td>\n      <td>...</td>\n      <td>0.004955</td>\n      <td>0.062660</td>\n      <td>0.009359</td>\n      <td>0.018818</td>\n      <td>0.000801</td>\n      <td>0.004604</td>\n      <td>0.071168</td>\n      <td>0.212402</td>\n      <td>0.615735</td>\n      <td>0.171863</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>97.0</td>\n      <td>4.333333</td>\n      <td>7.87</td>\n      <td>12.0</td>\n      <td>7.280875e+03</td>\n      <td>1.0</td>\n      <td>26.316354</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1790954.0</td>\n      <td>...</td>\n      <td>0.008414</td>\n      <td>0.064703</td>\n      <td>0.022922</td>\n      <td>0.031530</td>\n      <td>0.001016</td>\n      <td>0.001499</td>\n      <td>0.069491</td>\n      <td>0.253397</td>\n      <td>0.584748</td>\n      <td>0.161855</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>86.0</td>\n      <td>8.833333</td>\n      <td>7.83</td>\n      <td>15.0</td>\n      <td>7.556641e+05</td>\n      <td>371.0</td>\n      <td>80.896970</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>4284872.0</td>\n      <td>...</td>\n      <td>0.006153</td>\n      <td>0.072510</td>\n      <td>0.015524</td>\n      <td>0.027736</td>\n      <td>0.001136</td>\n      <td>0.003171</td>\n      <td>0.074404</td>\n      <td>0.251751</td>\n      <td>0.595418</td>\n      <td>0.152830</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99.0</td>\n      <td>7.600000</td>\n      <td>8.40</td>\n      <td>12.0</td>\n      <td>8.481321e+04</td>\n      <td>1.0</td>\n      <td>35.419410</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2984593.0</td>\n      <td>...</td>\n      <td>0.007098</td>\n      <td>0.063704</td>\n      <td>0.015899</td>\n      <td>0.020571</td>\n      <td>0.000652</td>\n      <td>0.004455</td>\n      <td>0.089816</td>\n      <td>0.258293</td>\n      <td>0.584673</td>\n      <td>0.157033</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>95.0</td>\n      <td>4.400000</td>\n      <td>7.27</td>\n      <td>16.0</td>\n      <td>2.739650e+04</td>\n      <td>6.0</td>\n      <td>77.544874</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2527673.0</td>\n      <td>...</td>\n      <td>0.008264</td>\n      <td>0.073509</td>\n      <td>0.024392</td>\n      <td>0.041586</td>\n      <td>0.001000</td>\n      <td>0.002932</td>\n      <td>0.107298</td>\n      <td>0.316295</td>\n      <td>0.481106</td>\n      <td>0.202599</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>88.0</td>\n      <td>7.000000</td>\n      <td>8.63</td>\n      <td>15.0</td>\n      <td>1.009349e+06</td>\n      <td>199.0</td>\n      <td>82.742644</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6367609.0</td>\n      <td>...</td>\n      <td>0.012921</td>\n      <td>0.042431</td>\n      <td>0.026320</td>\n      <td>0.028075</td>\n      <td>0.000319</td>\n      <td>0.005264</td>\n      <td>0.083107</td>\n      <td>0.233371</td>\n      <td>0.525443</td>\n      <td>0.241187</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>94.0</td>\n      <td>4.000000</td>\n      <td>6.55</td>\n      <td>12.0</td>\n      <td>6.336955e+06</td>\n      <td>1561.0</td>\n      <td>69.949808</td>\n      <td>32320.361940</td>\n      <td>960.0</td>\n      <td>5981221.0</td>\n      <td>...</td>\n      <td>0.013160</td>\n      <td>0.045036</td>\n      <td>0.039187</td>\n      <td>0.027782</td>\n      <td>0.000292</td>\n      <td>0.016815</td>\n      <td>0.087586</td>\n      <td>0.305746</td>\n      <td>0.471122</td>\n      <td>0.223132</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>97.0</td>\n      <td>7.000000</td>\n      <td>7.28</td>\n      <td>17.0</td>\n      <td>2.329598e+05</td>\n      <td>88.0</td>\n      <td>83.979676</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>977078.0</td>\n      <td>...</td>\n      <td>0.006675</td>\n      <td>0.072370</td>\n      <td>0.024943</td>\n      <td>0.027578</td>\n      <td>0.001230</td>\n      <td>0.005621</td>\n      <td>0.115054</td>\n      <td>0.324785</td>\n      <td>0.499210</td>\n      <td>0.176006</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>90.0</td>\n      <td>4.400000</td>\n      <td>8.70</td>\n      <td>21.0</td>\n      <td>4.214846e+04</td>\n      <td>9.0</td>\n      <td>74.211618</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2347377.0</td>\n      <td>...</td>\n      <td>0.008280</td>\n      <td>0.080457</td>\n      <td>0.044259</td>\n      <td>0.081849</td>\n      <td>0.001539</td>\n      <td>0.001539</td>\n      <td>0.108888</td>\n      <td>0.394006</td>\n      <td>0.452407</td>\n      <td>0.153587</td>\n    </tr>\n  </tbody>\n</table>\n<p>83 rows × 56 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-07T08:52:20.579447Z",
     "start_time": "2025-10-07T08:52:20.543599Z"
    }
   },
   "id": "4b0b0fc6daa796ba"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['No dementia', 'No dementia', 'No dementia', 'Dementia',\n       'No dementia', 'No dementia', 'Dementia', 'No dementia',\n       'No dementia', 'No dementia', 'Dementia', 'Dementia', 'Dementia',\n       'Dementia', 'No dementia', 'Dementia', 'No dementia',\n       'No dementia', 'No dementia', 'Dementia', 'Dementia',\n       'No dementia', 'Dementia', 'No dementia', 'Dementia',\n       'No dementia', 'No dementia', 'No dementia', 'Dementia',\n       'Dementia', 'No dementia', 'Dementia', 'Dementia', 'No dementia',\n       'No dementia', 'Dementia', 'Dementia', 'Dementia', 'Dementia',\n       'No dementia', 'No dementia', 'Dementia', 'No dementia',\n       'Dementia', 'Dementia', 'Dementia', 'Dementia', 'No dementia',\n       'Dementia', 'Dementia', 'No dementia', 'No dementia', 'Dementia',\n       'Dementia', 'Dementia', 'No dementia', 'Dementia', 'Dementia',\n       'No dementia', 'No dementia', 'No dementia', 'No dementia',\n       'Dementia', 'No dementia', 'Dementia', 'No dementia', 'Dementia',\n       'No dementia', 'No dementia', 'Dementia', 'No dementia',\n       'No dementia', 'No dementia', 'No dementia', 'Dementia',\n       'No dementia', 'No dementia', 'Dementia', 'Dementia', 'Dementia',\n       'Dementia', 'Dementia', 'No dementia'], dtype=object)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-07T08:52:27.108408Z",
     "start_time": "2025-10-07T08:52:27.082777Z"
    }
   },
   "id": "c313060a03c8a07d"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Define the cross-validation strategy (5 fold)\n",
    "N_SPLITS = 5\n",
    "outer_cv = GroupKFold(n_splits=N_SPLITS)\n",
    "inner_cv = GroupKFold(n_splits=N_SPLITS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:12.022118Z",
     "start_time": "2025-10-06T13:00:12.018051Z"
    }
   },
   "id": "8c0d83dd2cbfd5f0"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'L2 Regression (CV)': GridSearchCV(\n",
    "        estimator=LogisticRegression(\n",
    "            penalty='l2', solver='lbfgs', class_weight='balanced',\n",
    "            max_iter=3000, random_state=42\n",
    "        ),\n",
    "        param_grid={'C': np.logspace(-4, 1, 10)},\n",
    "        cv=inner_cv, scoring='roc_auc'\n",
    "    ),\n",
    "    'ElasticNet Regression (CV)': GridSearchCV(\n",
    "        estimator=LogisticRegression(\n",
    "            penalty='elasticnet', solver='saga', class_weight='balanced',\n",
    "            max_iter=3000, random_state=42\n",
    "        ),\n",
    "        param_grid={\n",
    "            'C': np.logspace(-4, 1, 10),\n",
    "            'l1_ratio': [0.25, 0.5, 0.75]\n",
    "        },\n",
    "        cv=inner_cv, scoring='roc_auc'\n",
    "    ),\n",
    "    # Aiming to mimicking the Firth Logistic Regression (by setting C = 0.01)\n",
    "    'L2 Regression (Strong Shrinkage C=0.01)': LogisticRegression( \n",
    "        penalty='l2', C=0.01, solver='lbfgs', class_weight='balanced',\n",
    "        max_iter=3000, random_state=42\n",
    "    )\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:26.034021Z",
     "start_time": "2025-10-06T13:00:26.007129Z"
    }
   },
   "id": "97863cc22eb28db3"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Define the feature preprocessing pipeline\n",
    "full_feature_list = FEATURE_MAP['M'] + FEATURE_MAP['Q'] + FEATURE_MAP['O']\n",
    "X_full = X[full_feature_list]\n",
    "\n",
    "numerical_features_full = X_full.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features_full = X_full.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "full_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_full),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_full)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:26.999957Z",
     "start_time": "2025-10-06T13:00:26.995933Z"
    }
   },
   "id": "824567a2251d86c5"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# 包含插补的完整数值和分类转换器\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "full_preprocessor_with_impute = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features_full),\n",
    "        ('cat', categorical_transformer, categorical_features_full)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:00:29.881247Z",
     "start_time": "2025-10-06T13:00:29.865949Z"
    }
   },
   "id": "1a296e08e79c35f1"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model: L2 Regression (CV) ---\n",
      "\n",
      "--- Evaluating Model: ElasticNet Regression (CV) ---\n",
      "\n",
      "--- Evaluating Model: L2 Regression (Strong Shrinkage C=0.01) ---\n",
      "\n",
      "--- Model Comparison Results ---\n",
      "                                              Accuracy      Precision  \\\n",
      "L2 Regression (CV)                       0.829 ± 0.075  0.868 ± 0.113   \n",
      "ElasticNet Regression (CV)               0.830 ± 0.049  0.847 ± 0.088   \n",
      "L2 Regression (Strong Shrinkage C=0.01)  0.771 ± 0.061  0.836 ± 0.083   \n",
      "\n",
      "                                                Recall       F1-score  \\\n",
      "L2 Regression (CV)                       0.803 ± 0.102  0.826 ± 0.072   \n",
      "ElasticNet Regression (CV)               0.825 ± 0.127  0.825 ± 0.058   \n",
      "L2 Regression (Strong Shrinkage C=0.01)  0.678 ± 0.173  0.733 ± 0.099   \n",
      "\n",
      "                                              AUC     AUC (95% CI)  \\\n",
      "L2 Regression (CV)                       0.918849  (0.850 - 0.987)   \n",
      "ElasticNet Regression (CV)               0.918849  (0.859 - 0.979)   \n",
      "L2 Regression (Strong Shrinkage C=0.01)  0.860466  (0.809 - 0.912)   \n",
      "\n",
      "                                                PR-AUC    Brier Score  \n",
      "L2 Regression (CV)                       0.904 ± 0.100  0.118 ± 0.038  \n",
      "ElasticNet Regression (CV)               0.904 ± 0.088  0.115 ± 0.035  \n",
      "L2 Regression (Strong Shrinkage C=0.01)  0.852 ± 0.098  0.192 ± 0.024  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of different models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"\\n--- Evaluating Model: {name} ---\")\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', full_preprocessor_with_impute),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "    aucs, pr_aucs, brier_scores = [], [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X_full, Y, groups)):\n",
    "        X_train, X_test = X_full.iloc[train_idx], X_full.iloc[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        groups_train = groups[train_idx]\n",
    "        \n",
    "        if isinstance(model, GridSearchCV):\n",
    "            pipeline.fit(X_train, y_train, classifier__groups=groups_train)\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "        pos_label = 'Dementia'\n",
    "        pos_index = list(pipeline.classes_).index(pos_label)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test)[:, pos_index]\n",
    "        y_pred = pipeline.predict(X_test) \n",
    "        \n",
    "        y_test_bin = np.where(y_test == pos_label, 1, 0)\n",
    "        \n",
    "        accuracies.append(accuracy_score(y_test, y_pred)) \n",
    "        precisions.append(precision_score(y_test, y_pred, pos_label=pos_label, zero_division=0)) \n",
    "        recalls.append(recall_score(y_test, y_pred, pos_label=pos_label, zero_division=0)) \n",
    "        f1s.append(f1_score(y_test, y_pred, pos_label=pos_label, zero_division=0)) \n",
    "        \n",
    "        aucs.append(roc_auc_score(y_test_bin, y_pred_proba))\n",
    "        pr_aucs.append(average_precision_score(y_test_bin, y_pred_proba))\n",
    "        brier_scores.append(brier_score_loss(y_test_bin, y_pred_proba))\n",
    "\n",
    "    auc_mean = np.mean(aucs)\n",
    "    auc_std = np.std(aucs)\n",
    "\n",
    "    auc_se = auc_std / np.sqrt(len(aucs))\n",
    "    \n",
    "    auc_ci_low = auc_mean - 1.96 * auc_se\n",
    "    auc_ci_high = auc_mean + 1.96 * auc_se\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'Accuracy': f\"{np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\", \n",
    "        'Precision': f\"{np.mean(precisions):.3f} ± {np.std(precisions):.3f}\", \n",
    "        'Recall': f\"{np.mean(recalls):.3f} ± {np.std(recalls):.3f}\", \n",
    "        'F1-score': f\"{np.mean(f1s):.3f} ± {np.std(f1s):.3f}\",\n",
    "        'AUC': auc_mean, \n",
    "        'AUC (95% CI)': f\"({auc_ci_low:.3f} - {auc_ci_high:.3f})\", \n",
    "        'PR-AUC': f\"{np.mean(pr_aucs):.3f} ± {np.std(pr_aucs):.3f}\", \n",
    "        'Brier Score': f\"{np.mean(brier_scores):.3f} ± {np.std(brier_scores):.3f}\" \n",
    "    }\n",
    "\n",
    "print(\"\\n--- Model Comparison Results ---\")\n",
    "model_results_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "\n",
    "display_cols = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC', 'AUC (95% CI)', 'PR-AUC', 'Brier Score']\n",
    "print(model_results_df[display_cols].sort_values(by='AUC', ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:05:32.543180Z",
     "start_time": "2025-10-06T13:05:17.450396Z"
    }
   },
   "id": "4f4424697b2c8b3b"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Evaluate the incremental value of different feature combinations\n",
    "# Here we select the best-performing model --- ElasticNet Regression (CV)\n",
    "best_model = classifiers['ElasticNet Regression (CV)']\n",
    "\n",
    "block_combinations = {\n",
    "    'M-Only (Clinical Baseline)': FEATURE_MAP['M'],\n",
    "    'M+Q': FEATURE_MAP['M'] + FEATURE_MAP['Q'],\n",
    "    'M+O': FEATURE_MAP['M'] + FEATURE_MAP['O'],\n",
    "    'M+Q+O (Full Model)': full_feature_list\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:07:30.452524Z",
     "start_time": "2025-10-06T13:07:30.445654Z"
    }
   },
   "id": "24a68050db0594f4"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "results_by_block = {}\n",
    "\n",
    "for name, feature_list in block_combinations.items():\n",
    "\n",
    "    X_block = X[feature_list]\n",
    "    \n",
    "    numerical_features_block = X_block.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_features_block = X_block.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "    block_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features_block),\n",
    "            ('cat', categorical_transformer, categorical_features_block)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', block_preprocessor),\n",
    "        ('classifier', best_model) \n",
    "    ])\n",
    "\n",
    "    aucs, pr_aucs, brier_scores = [], [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X_block, Y, groups)):\n",
    "        X_train, X_test = X_block.iloc[train_idx], X_block.iloc[test_idx]\n",
    "        y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "        groups_train = groups[train_idx]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train, classifier__groups=groups_train)\n",
    "        \n",
    "        pos_label = 'Dementia'\n",
    "        pos_index = list(pipeline.classes_).index(pos_label)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test)[:, pos_index]\n",
    "        y_test_bin = np.where(y_test == pos_label, 1, 0)\n",
    "        \n",
    "        aucs.append(roc_auc_score(y_test_bin, y_pred_proba))\n",
    "        pr_aucs.append(average_precision_score(y_test_bin, y_pred_proba))\n",
    "        brier_scores.append(brier_score_loss(y_test_bin, y_pred_proba))\n",
    "        \n",
    "    results_by_block[name] = {\n",
    "        'AUC Mean': np.mean(aucs),\n",
    "        'AUC Std': np.std(aucs),\n",
    "        'PR-AUC Mean': np.mean(pr_aucs),\n",
    "        'Brier Score Mean': np.mean(brier_scores),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:16:15.072890Z",
     "start_time": "2025-10-06T13:15:37.011257Z"
    }
   },
   "id": "625b4a1a5cd82be6"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Block Incremental Value Results ---\n",
      "                            AUC Mean   AUC Std  Brier Score Mean  Features\n",
      "M+Q                         0.937302  0.069207          0.106536        46\n",
      "M-Only (Clinical Baseline)  0.926190  0.062371          0.094102        37\n",
      "M+O                         0.924802  0.062025          0.095088        47\n",
      "M+Q+O (Full Model)          0.918849  0.068785          0.114519        56\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Feature Block Incremental Value Results ---\")\n",
    "results_df = pd.DataFrame.from_dict(results_by_block, orient='index')\n",
    "results_df['Features'] = [len(block_combinations[name]) for name in results_df.index]\n",
    "print(results_df[['AUC Mean', 'AUC Std', 'Brier Score Mean', 'Features']].sort_values(by='AUC Mean', ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-06T13:08:09.854908Z",
     "start_time": "2025-10-06T13:08:09.851548Z"
    }
   },
   "id": "8845292f0e59172b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
